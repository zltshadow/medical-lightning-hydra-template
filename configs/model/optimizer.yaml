optimizer:
  _target_: torch.optim.Adam
  _partial_: true
  lr: 1e-5

scheduler:
  _target_: torch.optim.lr_scheduler.ReduceLROnPlateau
  _partial_: true
  mode: min
  factor: 0.1
  patience: 100
  # _target_: monai.optimizers.WarmupCosineSchedule
  # _partial_: true
  # warmup_steps: 5
  # t_total: ${trainer.max_epochs}

loss_name: ce
# compile model for faster training with pytorch 2.0
compile: false